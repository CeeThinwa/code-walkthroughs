{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "double-dynamics",
   "metadata": {},
   "source": [
    "# Image block segmentation\n",
    "\n",
    "There are subcomponents in each print image, and the first task is to pick them out based on height.\n",
    "\n",
    "## I) Image importation\n",
    "\n",
    "Let's assume we want to break up the image below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tender-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\ct\\documents\\github\\code-walkthroughs\\venv\\lib\\site-packages (9.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ct\\documents\\github\\code-walkthroughs\\venv\\lib\\site-packages (1.21.6)\n",
      "Requirement already satisfied: pythonRLSA in c:\\users\\ct\\documents\\github\\code-walkthroughs\\venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ct\\documents\\github\\code-walkthroughs\\venv\\lib\\site-packages (from pythonRLSA) (1.21.6)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\ct\\documents\\github\\code-walkthroughs\\venv\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\ct\\documents\\github\\code-walkthroughs\\venv\\lib\\site-packages (from opencv-python-headless) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow\n",
    "!pip install numpy\n",
    "!pip install pythonRLSA\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "human-salvation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pythonRLSA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a6e427f6c3bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m# Numpy package\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpythonRLSA\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrlsa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pythonRLSA'"
     ]
    }
   ],
   "source": [
    "from PIL import Image # Pillow package\n",
    "import cv2 # Open CV package\n",
    "import numpy as np # Numpy package\n",
    "import math\n",
    "from pythonRLSA import rlsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sample_image_path = \"./kip-images/17_12_2021_Nation_MyNetWork_pg9.jpg\"\n",
    "    img = Image.open(sample_image_path)\n",
    "except:\n",
    "    sample_image_path = \"/home/jovyan/book/kenyans-in-print/kip-images/17_12_2021_Nation_MyNetWork_pg9.jpg\"\n",
    "    img = Image.open(sample_image_path)\n",
    "\n",
    "\n",
    "width, height = img.size\n",
    "display(img.resize(\n",
    "    (int(width*0.2),int(height*0.2))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-integration",
   "metadata": {},
   "source": [
    "How can we \"read\" the article above in a programmatic way?\n",
    "\n",
    "We would need to isolate various elements in the photo like the title and captions, which are larger than the body text.\n",
    "\n",
    "Luckily, with AI and OCR technologies, we can do just that.\n",
    "\n",
    "<br>\n",
    "\n",
    "## II) Use of the height heuristics approach\n",
    "\n",
    "Distinguishing between content elements vertically has 3 key steps:\n",
    "\n",
    "* Convert image to grayscale image, then binary image\n",
    "* Find contours based on binary grayscale\n",
    "* Use height heuristics to get indivisual regions in the image taller than others.\n",
    "\n",
    "### Round One\n",
    "\n",
    "üëáüèæ Reading the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(sample_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-stack",
   "metadata": {},
   "source": [
    "üëáüèæ Converting the image to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-marina",
   "metadata": {},
   "source": [
    "üëáüèæ Converting the image to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(thresh, binary) = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY |\n",
    "                                 cv2.THRESH_OTSU)\n",
    "\n",
    "im_pil = Image.fromarray(binary)\n",
    "\n",
    "display(im_pil.resize(\n",
    "    (int(width*0.2),int(height*0.2))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-questionnaire",
   "metadata": {},
   "source": [
    "üëáüèæ Identify contours and put bounding boxes around each letter or symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "(contours, _) = cv2.findContours(~binary,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "for contour in contours:\n",
    "    \"\"\"\n",
    "    draw a rectangle around those contours on main image\n",
    "    \"\"\"\n",
    "    [x,y,w,h] = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (0, 255, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "im_pil = Image.fromarray(image)\n",
    "\n",
    "# CODE CHECK CELL\n",
    "display(im_pil.resize(\n",
    "    (int(width*0.2),int(height*0.2))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-alabama",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://stackoverflow.com/questions/10262600/how-to-detect-region-of-large-of-white-pixels-using-opencv#10266717\n",
    "\n",
    "https://www.geeksforgeeks.org/python-pil-image-crop-method/\n",
    "\n",
    "https://machinelearningknowledge.ai/how-to-scale-and-resize-image-in-python-with-opencv-cv2-resize/\n",
    "\n",
    "https://stackoverflow.com/questions/43232813/convert-opencv-image-format-to-pil-image-format#43234001\n",
    "\n",
    "https://www.freedomvc.com/index.php/2021/06/26/contours-and-bounding-boxes/\n",
    "\n",
    "https://stackoverflow.com/questions/33299412/article-extraction-from-newspaper-image-in-python-and-opencv\n",
    "\n",
    "https://medium.com/@vasista/extract-title-from-the-image-documents-in-python-application-of-rlsa-58f91237901f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
